version: "3.8"
   
services:
  triton:
    image: nvcr.io/nvidia/tritonserver:20.09-py3
    command: tritonserver --model-repository=/models --strict-model-config=False --model-control-mode=explicit
    shm_size: '2gb'
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    volumes:
      - model-repository:/models
  api:
    build: 
      context: .
      dockerfile: proteus_api/Dockerfile
    ports:
      - "80:80"
    depends_on:
      - triton
    volumes:
      - model-repository:/models
      - logs:/logs
      - ./packages:/packages
    environment:
      - LOGLEVEL=INFO
      - MAX_ACTIVE_MODELS=3
      - MODEL_INACTIVITY=1

volumes:
  model-repository: 
  logs: